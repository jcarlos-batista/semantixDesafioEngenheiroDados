{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Técnico - Engenheiro de Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> Qual o objetivo do comando cache em Spark?</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "O Objetivo do comando cache e através de uma variável guardar os dados ou melhor armazenar os dados na memória assim irá melhorar o tempo de processamento e irá aumentar a velocidade de suas execuções. Com isso poderemos utilizar está variável em qualquer outra execução sem afetar nos processamento e teremos um maior ganho na performance.\n",
    "Isso lembra do Oracle quando temos os processamentos que são executados dentro da SGA os processos de background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> O mesmo código implementado em Spark é normalmente mais rápido que a implementação equivalente em MapReduce. Por quê?</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A vantagem do Spark e que ele estende o modelo Map/Reduce para utilizar com maior eficiência diferentes tipos de computação.\n",
    "Foi desenvolvido para solucionar o paradigma da computação em cluster do Map/Reduce, que força uma estrutura linear de fluxo de dados em programas distribuídos (map -> shuffle -> reduce).\n",
    "Uma das principais características do Spark é a computação em cluster em memória, que aumenta consideravelmente a velocidade de processamento.\n",
    "Spark chega a processar dados do disco 10x mais rápido que o Map/Reduce e 100x mais rápido ao processar dados da memória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> Qual é a função do SparkContext?</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Principal ponto de entrada para a funcionalidade Spark. \n",
    "Um SparkContext representa a conexão com um cluster Spark e pode ser usado para criar RDDs, acumuladores e variáveis de transmissão nesse cluster.\n",
    "Apenas um SparkContext pode estar ativo por JVM. Você deve stop()o SparkContext ativo antes de criar um novo. Essa limitação pode eventualmente ser removida; veja SPARK-2243 para mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">-> Explique com suas palavras o que é Resilient Distributed Datasets (RDD).</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- É uma estrutura fundamental para que o Spark funcione conforme planejado;\n",
    "- É uma coleção de objetos distribuídos constante (no sentido de permanente, imutável);\n",
    "- Tal coleção pode ser armazenada em memória ou em disco (HDFS, entre outros);\n",
    "- Pode ser convertido em outro RDD através de” transformações”;\n",
    "- Cada dataset é dividido em unidades lógicas que podem ser processadas em diferentes nós do cluster;\n",
    "- É uma coleção de elementos tolerante a falhas que pode ser processada em paralelo;\n",
    "\n",
    "Há duas maneiras de criar um RDD:\n",
    "- Paralelizando uma coleção de dados existente no programa principal;\n",
    "- Referenciando um dataset em um sistema de armazenamento externo, como um sistema de arquivos compartilhado, HDFS, GFS, HBase ou qualquer fonte de dados que possua um formato de entrada\n",
    "do Hadoop;\n",
    "\n",
    "Em resumo, o Spark utiliza os conceitos do RDD para realizar operações de Map/Reduce de maneira mais rápida e mais eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">-> GroupByKey é menos eficiente que reduceByKey em grandes dataset. Por quê?</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupByKey: Pode causar problemas de falta de disco à medida que os dados são enviados pela rede e coletados nos trabalhadores de redução.\n",
    "\n",
    "reduceByKey: Os dados são combinados em cada partição, apenas uma saída para uma chave em cada partição a ser enviada pela rede. reduzaByKey necessário combinando todos os seus valores em outro valor com exatamente o mesmo tipo.\n",
    "\n",
    "Resumindo:\n",
    "groupByKey()é apenas para agrupar seu conjunto de dados com base em uma chave. Isso resultará no embaralhamento de dados quando o RDD ainda não estiver particionado.\n",
    "reduceByKey()é algo como agrupamento + agregação. Podemos dizer que reduzaBykey () equivalente a dataset.group (...). Reduza (...). Ao contrário, embaralha menos dados groupByKey()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">-> Explique o que o código Scala abaixo faz.</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# val textFile = sc.textFile(\"hdfs://...\") \t\t\t\t   -- Foi atribuído a variável \"var\" um arquivo texto, o qual está em uma estrutura do HDFS.\n",
    "\n",
    "    val counts = textFile.flatMap(line => line.split(\" \")) -- realiza a contagem do conteúdo já splitado.\n",
    "\t.map(word=>(word,1)) \t\t\t\t\t\t\t\t   -- Com o comando map ele atribui a cada palavra um valor 1.\n",
    "\t.reduceByKey(_+_)                                      -- O reduce irá reduzir eliminando as palavras duplicadas.\n",
    "counts.saveAsTextFile(\"hdfs://...\")                        -- Salvando o resultado de counts em um novo arquivo no hdfs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABORATORIO \n",
    "HTTP requests to the NASA Kennedy Space Center WWW server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando ambiente para análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> Importação de Bibliotecas</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da biblioteca para trabalhar em memoria\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> Configuração do SparkSession</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('desafioEngenhariaDados').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> -> Importação de logs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivo <font color=\"red\">\"access_log_Jul95\"</font> com logs de Julho de 1995 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logJul95 = sc.textFile('arquivos/access_log_Jul95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logJul95.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivo <font color=\"red\">\"access_log_Aug95\"</font> com logs de Agosto de 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logAug95 = sc.textFile('arquivos/access_log_Aug95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in24.inetnebr.com - - [01/Aug/1995:00:00:01 -0400] \"GET /shuttle/missions/sts-68/news/sts-68-mcc-05.txt HTTP/1.0\" 200 1839',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:07 -0400] \"GET / HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 304 0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logAug95.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos concatenar os dois arquivos para melhor analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_total = logJul95 + logAug95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionRDD[6] at union at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_total.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0',\n",
       " '205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n",
       " '129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204',\n",
       " '129.94.144.152 - - [01/Jul/1995:00:00:17 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:17 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713',\n",
       " 'ppptky391.asahi-net.or.jp - - [01/Jul/1995:00:00:18 -0400] \"GET /facts/about_ksc.html HTTP/1.0\" 200 3977',\n",
       " 'net-1-141.eden.com - - [01/Jul/1995:00:00:19 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0916.jpg HTTP/1.0\" 200 34029']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_total.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio da análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[12] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processo de mapeamento e reduce \n",
    "numeroHost = log_total.map(lambda line: line.split(\" \")[0]) \\\n",
    "    .map(lambda value: (value, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \n",
    "\n",
    "numeroHost.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unicomp6.unicomp.net', 14),\n",
       " ('dial22.lloyd.com', 4),\n",
       " ('www-a1.proxy.aol.com', 6661),\n",
       " ('dave.dev1.ihub.com', 4),\n",
       " ('brandt.xensei.com', 80),\n",
       " ('dnet018.sat.texas.net', 71),\n",
       " ('166.79.67.111', 17),\n",
       " ('dynip38.efn.org', 17),\n",
       " ('piweba1y.prodigy.com', 12825),\n",
       " ('oahu-53.u.aloha.net', 7)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validando execução\n",
    "numeroHost.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o numero de Host e atribuindo a variavel quest01\n",
    "quest01 = numeroHost.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando os erros\n",
    "totalError = log_total.filter(lambda line: \" 404 -\"  in line or \" 404 0\" in line)\n",
    "\n",
    "totalError.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o numero de erros com count\n",
    "quest02 = totalError.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[27] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 URLS que mais causaram erro 404\n",
    "\n",
    "totalURLerro = log_total.filter(lambda line: line.split(\" \")[0] and \" 404 -\"  in line or \" 404 0\" in line) \\\n",
    "    .map(lambda line: line.split(\" \")[0]) \\\n",
    "    .map(lambda value: (value, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "totalURLerro.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "errosURL = totalURLerro.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest03 = dados.DataFrame(errosURL, columns=[\"NOME DAS URLS\",\"QTD. DOS ERROS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">RESULTADO</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">1. Número de hosts únicos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts únicos é: 137979\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de hosts únicos é:\",quest01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">2. O total de erros 404.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de erros 404 é: 20901\n"
     ]
    }
   ],
   "source": [
    "print(\"O total de erros 404 é:\", quest02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> 3. Os 5 URLs que mais causaram erro 404.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As 5 URLs que mais causaram erro 404 foram asseguintes abaixo:\n",
      "                  NOME DAS URLS  QTD. DOS ERROS\n",
      "0         hoohoo.ncsa.uiuc.edu             251\n",
      "1         piweba3y.prodigy.com             157\n",
      "2  jbiagioni.npt.nuwc.navy.mil             132\n",
      "3         piweba1y.prodigy.com             114\n",
      "4         www-d4.proxy.aol.com              91 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"As 5 URLs que mais causaram erro 404 foram asseguintes abaixo:\\n\", quest03, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Não consegui responder as proximas perguntas devido a erros apresentado nas funções que estava criando.</font>\n",
    "### <font color=\"red\">Devido ao tempo não pude completar estas duas etapas abaixo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> 4. Quantidade de erros 404 por dia.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> 5. O total de bytes retornados.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
